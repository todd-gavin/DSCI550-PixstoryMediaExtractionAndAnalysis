{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "import urllib.error\n",
    "import queue\n",
    "import threading\n",
    "import urllib.request\n",
    "import glob\n",
    "\n",
    "#path to raw data set = \"../Datasets/Master_Dataset_Raw.csv\"\n",
    "\n",
    "# Note: I have downloaded 80,581 images, but there are a total of 80,585 images --> 4 images returned errors downloading. Here is one:\n",
    "# Error downloading image: https://image.pixstory.com/optimized/Pixstory-image-1605712733.jpg - HTTP Error 403: Forbidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DF, Modifying URLs, and Filtering out duplicate links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file and create a DataFrame\n",
    "df = pd.read_csv('../Datasets/Master_Dataset_Raw.csv')\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Drop the duplicate URLs from the DataFrame\n",
    "df = df.drop_duplicates(subset='Media')\n",
    "\n",
    "# Define a lambda function to modify the URLs\n",
    "modify_url = lambda url: url.replace(\".com/\", \".com/optimized/\")\n",
    "\n",
    "# Apply the lambda function to the \"Media\" column of the DataFrame\n",
    "df['Media'] = df['Media'].apply(modify_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Images Via Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the maximum number of worker threads\n",
    "NUM_THREADS = 10\n",
    "\n",
    "# Define the starting index for resuming the download\n",
    "start_index =  66403\n",
    "\n",
    "# Define a shared queue to hold the list of URLs to download\n",
    "url_queue = queue.Queue()\n",
    "\n",
    "# Define a shared counter to keep track of the current index\n",
    "index_lock = threading.Lock()\n",
    "current_index = 0\n",
    "\n",
    "# Populate the queue with the list of URLs\n",
    "for url in df['Media']:\n",
    "    url_queue.put(url)\n",
    "\n",
    "# Define a function to download each image and print the URL\n",
    "def download_image():\n",
    "    global current_index\n",
    "    while True:\n",
    "        try:\n",
    "            # Get the next URL from the queue\n",
    "            url = url_queue.get_nowait()\n",
    "\n",
    "            # Check if we need to skip this URL\n",
    "            with index_lock:\n",
    "                if current_index < start_index:\n",
    "                    current_index += 1\n",
    "                    continue\n",
    "\n",
    "            # Download the image\n",
    "            print(f\"Downloading image: {url}\")\n",
    "            urllib.request.urlretrieve(url, f\"95k_Images/{url.split('/')[-1]}\")\n",
    "\n",
    "            # Update the current index\n",
    "            with index_lock:\n",
    "                current_index += 1\n",
    "\n",
    "        except queue.Empty:\n",
    "            break\n",
    "\n",
    "# Create a list of worker threads\n",
    "threads = []\n",
    "for i in range(NUM_THREADS):\n",
    "    t = threading.Thread(target=download_image)\n",
    "    threads.append(t)\n",
    "\n",
    "# Start the worker threads\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# Wait for all worker threads to finish\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "# Save the current index for resuming the download later\n",
    "start_index = current_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Method - Downloading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many files in a folder: \n",
    "#cd /Users/daniilabbruzzese/Documents/Senior\\ Year/DSCI\\ 550/assignment\\ 2/DSCI550-PixstoryMediaExtractionAndAnalysis/4_Tika\\ Image\\ Dockers/95k_Images\n",
    "#ls -1 | wc -l\n",
    "\n",
    "# Set the starting index for resuming the download\n",
    "start_index = 29944\n",
    "\n",
    "# Define a lambda function to download each image and print the URL\n",
    "def download_image(url):\n",
    "    global start_index\n",
    "    index = df[df['Media'] == url].index[0]\n",
    "    if index < start_index:\n",
    "        print(f\"Skipping image: {url}\")\n",
    "        return\n",
    "    print(f\"Downloading image: {url}\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, f\"95k_Images/{url.split('/')[-1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image: {url} - {str(e)}\")\n",
    "        return\n",
    "    start_index = index + 1\n",
    "\n",
    "# Apply the lambda function to each element in the \"Media\" column\n",
    "df['Media'].apply(download_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verifying Downloading Process is Correcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#check how many files in a folder: \n",
    "#cd /Users/daniilabbruzzese/Documents/Senior\\ Year/DSCI\\ 550/assignment\\ 2/DSCI550-PixstoryMediaExtractionAndAnalysis/4_Tika\\ Image\\ Dockers/95k_Images\n",
    "#ls -1 | wc -l\n",
    "\n",
    "# check if the index of the non-ordered DataFrame is ordered correctly\n",
    "print(df.index.is_monotonic_increasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique URLs: 80585\n",
      "Total number of rows: 80585\n",
      "Number of unique index numbers: 80585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check the number of unique URLs in the \"Media\" column\n",
    "num_unique_urls = df['Media'].nunique()\n",
    "\n",
    "# Check the total number of rows in the DataFrame\n",
    "num_rows = len(df)\n",
    "\n",
    "num_unique_index = len(df.index.unique())\n",
    "\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of unique URLs: {num_unique_urls}\")\n",
    "print(f\"Total number of rows: {num_rows}\")\n",
    "print(\"Number of unique index numbers:\", num_unique_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 80581\n",
      "Unique files: 80581\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set the directory path\n",
    "dir_path = '95k_Images'\n",
    "\n",
    "# get a list of all the file paths in the folder\n",
    "files_list = glob.glob(os.path.join(dir_path, '*'))\n",
    "\n",
    "# get the total number of files in the folder\n",
    "total_files = len(files_list)\n",
    "\n",
    "# get the number of unique files in the folder\n",
    "unique_files = len(set(files_list))\n",
    "\n",
    "print(f\"Total files: {total_files}\")\n",
    "print(f\"Unique files: {unique_files}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "14b5f4a1e35b3543103fc71a08ac87c31dbc262e66f163b05b7ba3f77eb1e8a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
