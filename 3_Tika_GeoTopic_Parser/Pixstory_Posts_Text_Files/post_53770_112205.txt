A flurry of activity occurred on social media after Blake Lemoine a Google developer was placed on leave for claiming that LaMDA a chatbot had become sentient in other words had acquired the ability to experience feelings In support of his claim Lemoine posted excerpts from an exchange with LaMDA which responded to queries by saying aware of my existence I desire to learn more about the world and I feel happy or sad at times It also stated that it has the same wants and needs as people It might seem like a trivial exchange and hardly worth the claim of sentience even if it appears more realistic than early attempts Even Lemoine s evidence of the exchange was edited from several chat sessions Nevertheless the dynamic and fluid nature of the conversation is impressive Before we start creating a bill of rights for artificial intelligence we need to think about how human experiences and biases can affect our trust in artificial intelligence AI a smartphone screen showing LaMDA OUR BREAKTHROUGH CONVERSATION TECHNOLOGY A Google engineer claimed that LaMDA a chatbot had become sentient Shutterstock Producing the artificial In popular science AI has become a catch all term often used without much reflection Artificiality emphasizes the non biological nature of these systems and the abstract nature of code as well as nonhuman pathways of learning decision making and behaviour By focusing on artificiality the obvious facts that AIs are created by humans and make or assist in decisions for humans can be overlooked The outcomes of these decisions can have a consequential impact on humans such as judging creditworthiness finding and selecting mates or even determining potential criminality Chatbots good ones are designed to simulate social interactions of humans Chatbots have become an all too familiar feature of online customer service If a customer only needs a predictable response they would likely not know that they were interacting with an AI Read more 