Artificial intelligence improvements have sped up the development of audio, video, and image modification capabilities. The availability of low-cost cloud computing, open-source AI methods, and large amounts of data has created a perfect storm for democratising the generation of deepfakes for mass distribution on social media platforms.

However, using deepfakes to create a false narrative is risky and can cause harm to individuals, society, and in this case, a country as a whole, both intentionally and unintentionally. Deepfakes have the potential to exacerbate the global post-truth dilemma since they are not only fake, but also extremely realistic, betraying our most basic senses of sight and sound. Putting words in someone else's mouth, switching a person's face for another, and constructing synthetic pictures and digital puppets of public personas to systematise deception are all ethically dubious behaviours that should be held accountable for the potential harm to persons and organisations.

While Russia's strategy of creating a deepfake could be considered as just another tactic to win the war—which it is— it does not change the fact that it is extremely unethical and oppressive to the targeted group. Fear mongering through misinformation has been a part of fighting wars for the longest time but just because it is the norm does not mean it is justifiable. This cyber attack on Ukraine by Russia is henceforth condemnable.

Deepfakes' weaponization can have a huge impact on the economy, personal liberty, and national security. They have massive ethical ramifications. As a result, they should be severely regulated, if not outright prohibited.