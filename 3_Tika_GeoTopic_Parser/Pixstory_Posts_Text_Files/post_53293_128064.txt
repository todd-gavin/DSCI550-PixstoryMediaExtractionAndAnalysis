How are social media platforms managing vaccine misinformation at this stage in the pandemic Anti vaccine sentiment has been building since and hasn t gone anywhere In fact it will have intensified following the recent approval of COVID vaccinations for some babies and children under five and the recommendation for a fourth booster shot for people over And although anti vaxxers can be found in most online spaces Facebook has historically been one of their platforms of choice Swinburne PhD student Damilola Ayeni has been interviewing anti vaccine activists since to learn about how they grow their audience on Facebook and how they evade moderation Her findings help shed light on the tug of war between Facebook s content moderation efforts and an unrelenting slew of vaccine misinformation What s been happening Facebook has been moderating content under the COVID and vaccine policy It does this by warning group admins and moderators deleting offending accounts or groups and flagging posts containing misinformation In its first response to Australia s DIGI Misinformation and Disinformation Code Facebook said it had removed over million pieces of content that constituted misinformation related to COVID of which were from Australian pages Despite this Facebook s moderation approach has loopholes that anti vaxxers continue to exploit For instance the ABC recently fact checked anti vaxxers who were spreading misinformation on Facebook by claiming COVID vaccines were responsible for the sudden death of a Queensland toddler Ayeni s research found anti vax Facebook groups are now self moderating This means they predict what Facebook s automated moderation tools and independent fact checkers will be looking for and change their posting techniques accordingly Read more 