{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec4e5b9",
   "metadata": {},
   "source": [
    "You need to make sure you have tika and get the docker image running with this command: \n",
    "\n",
    "IMAGE=tgowda/rtg-model:500toEng-v1\n",
    "\n",
    "docker run --platform linux/amd64 --rm -i -p 6060:6060 $IMAGE\n",
    "\n",
    "I added in  --platform Linux/amd64  to the command bc I’m on a mac and I needed that to run the image \n",
    "\n",
    "You’ll also need to pip install tika and emoji. I accidentally installed / imported requests too but didn’t end up using it \n",
    "\n",
    "Please make sure you have Java1.8 or higher intsalled on the environment you are using to run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "90c69ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tika import translate\n",
    "from tika import language\n",
    "import requests\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/Master_Dataset_Raw_LangDetect.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac6b6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Narrative'] = df['Narrative'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030131e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taken from the emoji docs since it's not in the latest versions\n",
    "def get_emoji_regexp():\n",
    "    # Sort emoji by length to make sure multi-character emojis are\n",
    "    # matched first\n",
    "    emojis = sorted(emoji.EMOJI_DATA, key=len, reverse=True)\n",
    "    pattern = u'(' + u'|'.join(re.escape(u) for u in emojis) + u')'\n",
    "    return re.compile(pattern)\n",
    "\n",
    "exp = get_emoji_regexp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc91127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        The colour of the year is here and it s drumro...\n",
      "1        We Indians do love to bastardise our foods Chi...\n",
      "2        Can professors not have personal lives Additio...\n",
      "3        She was recorded on video manhandling him shou...\n",
      "4        The House passed the Inflation Reduction Act o...\n",
      "                               ...                        \n",
      "94995                                           MODR CLASS\n",
      "94996    College life without a friend is useless Enjoy...\n",
      "94997               Sheridan college HazelMcCallion Canpus\n",
      "94998                                      Check this out \n",
      "94999    Spending time in college with these two maddie...\n",
      "Name: Narrative, Length: 95000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#this function removes any emojis, html tags, URLs, and special characters before translating\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        text = exp.sub(u'', text)\n",
    "        text = re.sub(r'<.*?>', '', text)\n",
    "        text = re.sub(r'http\\S+', '', text)\n",
    "        text = re.sub('[^a-zA-Z]+', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "    except :\n",
    "        print(text)\n",
    "    finally:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10f7a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_narr = clean_text(df['Narrative'].apply(clean_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7edf72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean Narrative'] = clean_narr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbe4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 2 #can increase this number, my computer couldn't even handle 2 words per translation\n",
    "\n",
    "translated_column = []\n",
    "for text, language in zip(df['Clean Narrative'], df['Narrative TikaDetect']):\n",
    "    if language != 'en':\n",
    "        words = text.split(\" \")\n",
    "        #translate the narrative in chunks depending on the limit set and join them all together at the end\n",
    "        if len(words) > chunks:\n",
    "            translated_chunks = []\n",
    "            try:\n",
    "                for i in range(0, len(words), chunks):\n",
    "                    group = ' '.join(words[i:i+chunks])\n",
    "                    translation = translate.from_buffer(group, language, 'en', requestOptions={'timeout':500})\n",
    "                    translated_chunks.append(translation)\n",
    "                translated_text = ' '.join(translated_chunks)\n",
    "                translated_column.append(translated_text)\n",
    "            except:\n",
    "                print(text)\n",
    "            finally:\n",
    "                #Appending \"redo\" for narratives that fail so they will be searchable to run again and update\n",
    "                translated_column.append('redo')\n",
    "        #translate the entire narrative if it's under the specified chunk size\n",
    "        else:\n",
    "            try:\n",
    "                translated_text = translate.from_buffer(text, language, 'en', requestOptions={'timeout':500})\n",
    "                translated_column.append(translated_text)\n",
    "            except:\n",
    "                print(text)\n",
    "            finally:\n",
    "                #Appending \"redo\" for narratives that fail so they will be searchable to run again and update\n",
    "                translated_column.append('redo')\n",
    "    else:\n",
    "        #just append the regular text if it's already english\n",
    "        translated_column.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e82d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Translated Narrative'] = translated_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6feebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Master_Dataset_Raw_LangDetect_Translated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
